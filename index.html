
<!DOCTYPE html>
<html version="0.1.0">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title></title>
	
	<link rel="stylesheet" type="text/css" href="css/notebooks.css" />
	<link rel="stylesheet" type="text/css" href="css/styles.css" />
</head>

<body>
<div class="outer-container">

  <div class="top">

  	<header>
		<div class="header-container">
			<h1>CapsNet tutorial - Sam Nguyen</h1>
		</div>
	</header>

  </div>

  <div class="content">

    <div id="left">

    	<div id="sidebar">
			<div class="sidebar__inner">
				<button id="expand-sidebar" class="btn btn-primary btn-xs">Expand</button>

				<div class="inner">
					<p>Hover or click on any <span class="hoverable">element</span> for comments.</p>
				</div>
			<div class="resize-sensor" style="position: absolute; left: 0px; top: 0px; right: 0px; bottom: 0px; overflow: hidden; z-index: -1; visibility: hidden;"><div class="resize-sensor-expand" style="position: absolute; left: 0; top: 0; right: 0; bottom: 0; overflow: hidden; z-index: -1; visibility: hidden;"><div style="position: absolute; left: 0px; top: 0px; transition: all 0s ease 0s; width: 100000px; height: 100000px;"></div></div><div class="resize-sensor-shrink" style="position: absolute; left: 0; top: 0; right: 0; bottom: 0; overflow: hidden; z-index: -1; visibility: hidden;"><div style="position: absolute; left: 0; top: 0; transition: 0s; width: 200%; height: 200%"></div></div></div></div>
		</div>

    </div>

    <!-- <div id="middle"></div> -->

    <div id="right" class="">

<!-- NOTEBOOK Container -->

<div id="content" class="link-textupline">
			<div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn" data-text="numpy is a TODO...">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn" data-text="importing PyTorch the library">import</span> <span class="nn">torch</span>
<span class="kn" data-text="PyTorch has various sub modules, one of which is nn and its function is to provide base models. Here we're importing the sub module nn from PyTorch and will invoke it as <b> nn </b> through out this script.">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn" data-text="autograd is another package provided by PyTorch. As the name suggests, autograd takes care of solving differentiation (gradients) automatically, so you can just focus on designing your networks/models instead of  cumbersome math equations. We'll see the use of autograd package throughout this notebook. I'll try to note them explicitly whenever possible.">torch.autograd</span> <span class="kn">import</span> <span class="n" data-text="Auto gradients (differentiation) is essentially carried out by keeping tracking track of how each variable is related to one another. If you know the state of the variable graph (and how they're related to one another), then differentiation with respect to a certain variable is just running a bunch of equations. <br> For example: if y = x^2. Here, Variable helps us keep track of the variable graph and do the heavy lifting of auto-grad-ing (?).">Variable</span>
<span class="kn">from</span> <span class="nn" data-text="yet another package from PyTorch! optim stands for optimization and is super useful whenever you want to optimize something, for example, a neural network! Training a network is essentially optimizing (turning the knobs, if you will) the network's weights.">torch.optim</span> <span class="kn">import</span> <span class="n" data-text="Adam is one of the popular optimization methods. It is special in that (TODO).">Adam</span>
<span class="kn">from</span> <span class="nn" data-text="this package specializes in helper methods useful for all things vision.">torchvision</span> <span class="kn">import</span> <span class="n" data-text="it has many useful methods dealing primarily with getting and saving datasets pertaining to computer vision, such as MNIST, CIFAR10, etc.">datasets</span><span class="p">,</span> <span class="n" data-text="after getting a dataset, it's often important to transform the raw data into more manageable format and/or normalize them. transform package has many helper methods that are useful for this purpose.">transforms</span>

<span class="n">USE_CUDA</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>

    </div>

<div>

</div>

</div>
</div>
</div>

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2" ><pre><span></span><span class="k">class</span> <span class="nc" data-text="getting the MNIST dataset and do some initial transformation. We're declaring a class here for later ease of use (TODO).">Mnist</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm" data-text="You probably already know about this, but for the sake of completion, __init__ method is Python's constructor -- it creates an instance of a class and does all the bootstrapping. You'll see this method all over the place!">__init__</span><span class="p">(</span><span class="bp" data-text="one thing that might be a bit baiz TODO">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="n">dataset_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n" data-text="Composing a set of transformations on the dataset. Note that the transformations will be applied in order. For example, here we're transforming the raw data list to PyTorch tensor and then normalizing the dataset.">Compose</span><span class="p">([</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n" data-text="transform the input to a PyTorch tensor, an essential data form of torch and it's important to get the hang of all the properties of a PyTorch tensor (TODO).">ToTensor</span><span class="p">(),</span>
                       <span class="n">transforms</span><span class="o">.</span><span class="n" data-text="normalize a tensor. To normalize some data, you'll need the center (mean) and standard devation (or variance). So the following seemingly `magic` numbers were the mean and standard deviation computed on the training set. It's good to note that the numbers were not calculated from the whole dataset (train + test), because if test data is involved, some info would be leaked to the network.">Normalize</span><span class="p">((</span><span class="mf">0.1307</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.3081</span><span class="p">,))</span>
                   <span class="p">])</span>

        <span class="n" data-text="because we're passing in the transformations defined above, the result will be MNIST training dataset that has already been transformed to PyTorch tensor and then normalized.">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n" data-text="invoking the MNIST function of the datasets module to get the MNIST dataset...">MNIST</span><span class="p">(</span><span class="s1" data-text="the data files will be saved here">&#39;../data&#39;</span><span class="p">,</span> <span class="n" data-text="get the train or test data? MNIST has 70000 images in total, 60000 for training and 10000 testing.">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n" data-text="If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. (PyTorch docs)">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n" data-text="the set of transformations to apply to this dataset">transform</span><span class="o">=</span><span class="n">dataset_transform</span><span class="p">)</span>
        <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">&#39;../data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp" data-text="False because we want the test set, not train set">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">dataset_transform</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n" data-text="TODO: give an example of how one can loop over a loader">train_loader</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n" data-text="DataLoader is a really useful method. When training a neural network, you'd want to train the network in mini batches of, say, 32 data items. The mini batches should also come in random order (stochastic). So you'd want a sampler that can yield (in Python terms) random batches of size 32, and that's what DataLoader is used for. It can also provide single- or multi-process iterators over the dataset.">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n" data-text="size of each batch of data items from the DataLoader. It's often a number that's power of 2 (16, 32, 128, 256, ...). For example, MNIST training set has 60,000 images. If batch size is chosen to be 64, DataLoader will yield 938 batches, the last of which has only 32 data items instead of 64 because 60,000/64 = 937.5). (TODO), how to choose a good batch size?">batch_size</span><span class="p">,</span> <span class="n" data-text="shuffle the dataset to yield the mini batches in a random order">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>        
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">class</span> <span class="nc" data-text="Our convolutional layer for the Capsule Net. In PyTorch, we create new customized layers by sub-classing the nn.Module class.">ConvLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n" data-text="sub-classing the nn.Module class, which is a base class for all customized layer in PyTorch (TODO): what basic functions need to be overridden?">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">9</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n" data-text="Convolutional layer module provided by the nn package from PyTorch TODO">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                               <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                               <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
                               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span>
                             <span class="p">)</span> <span data-template="templates/conv.html"># NOTE</span>

    <span class="k">def</span> <span class="nf" data-template="templates/forward.html">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n" data-template="templates/relu.html">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n" data-text="the Conv2d layer we've just defined above">conv</span><span class="p">(</span><span class="n">x</span><span class="p">))
        </span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">class</span> <span class="nc">PrimaryCaps</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_capsules</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">9</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PrimaryCaps</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">capsules</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> 
                          <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_capsules</span><span class="p">)])</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">u</span> <span class="o">=</span> <span class="p">[</span><span class="n">capsule</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">capsule</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">capsules</span><span class="p">]</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">squash</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">squash</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
        <span class="n">squared_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_tensor</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">squared_norm</span> <span class="o">*</span>  <span class="n">input_tensor</span> <span class="o">/</span> <span class="p">((</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">squared_norm</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">squared_norm</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output_tensor</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">class</span> <span class="nc">DigitCaps</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_capsules</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_routes</span><span class="o">=</span><span class="mi">32</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">*</span> <span class="mi">6</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DigitCaps</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_routes</span> <span class="o">=</span> <span class="n">num_routes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_capsules</span> <span class="o">=</span> <span class="n">num_capsules</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_routes</span><span class="p">,</span> <span class="n">num_capsules</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_capsules</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

        <span class="n">W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">u_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="n">b_ij</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_routes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_capsules</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">USE_CUDA</span><span class="p">:</span>
            <span class="n">b_ij</span> <span class="o">=</span> <span class="n">b_ij</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
            <span class="n">c_ij</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">b_ij</span><span class="p">)</span>
            <span class="n">c_ij</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">c_ij</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

            <span class="n">s_j</span> <span class="o">=</span> <span class="p">(</span><span class="n">c_ij</span> <span class="o">*</span> <span class="n">u_hat</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">v_j</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">squash</span><span class="p">(</span><span class="n">s_j</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">iteration</span> <span class="o">&lt;</span> <span class="n">num_iterations</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">a_ij</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u_hat</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">v_j</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_routes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">b_ij</span> <span class="o">=</span> <span class="n">b_ij</span> <span class="o">+</span> <span class="n">a_ij</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">v_j</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">squash</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
        <span class="n">squared_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_tensor</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">squared_norm</span> <span class="o">*</span>  <span class="n">input_tensor</span> <span class="o">/</span> <span class="p">((</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">squared_norm</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">squared_norm</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output_tensor</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">class</span> <span class="nc" data-text="But why do we need this?">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">reconstraction_layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">classes</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
        
        <span class="n">_</span><span class="p">,</span> <span class="n">max_length_indices</span> <span class="o">=</span> <span class="n">classes</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">masked</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">USE_CUDA</span><span class="p">:</span>
            <span class="n">masked</span> <span class="o">=</span> <span class="n">masked</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">masked</span> <span class="o">=</span> <span class="n">masked</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">max_length_indices</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        
        <span class="n">reconstructions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reconstraction_layers</span><span class="p">((</span><span class="n">x</span> <span class="o">*</span> <span class="n">masked</span><span class="p">[:,</span> <span class="p">:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">reconstructions</span> <span class="o">=</span> <span class="n">reconstructions</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">reconstructions</span><span class="p">,</span> <span class="n">masked</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="k">class</span> <span class="nc">CapsNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CapsNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_layer</span> <span class="o">=</span> <span class="n">ConvLayer</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">primary_capsules</span> <span class="o">=</span> <span class="n">PrimaryCaps</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">digit_capsules</span> <span class="o">=</span> <span class="n">DigitCaps</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">()</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">digit_capsules</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">primary_capsules</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_layer</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
        <span class="n">reconstructions</span><span class="p">,</span> <span class="n">masked</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">,</span> <span class="n">masked</span>
    
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">margin_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">reconstruction_loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">margin_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">v_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>

        <span class="n">left</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="mf">0.9</span> <span class="o">-</span> <span class="n">v_c</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">right</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">v_c</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">*</span> <span class="n">left</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">labels</span><span class="p">)</span> <span class="o">*</span> <span class="n">right</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">loss</span>
    
    <span class="k">def</span> <span class="nf">reconstruction_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">reconstructions</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">reconstructions</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">reconstructions</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">loss</span> <span class="o">*</span> <span class="mf">0.0005</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">capsule_net</span> <span class="o">=</span> <span class="n">CapsNet</span><span class="p">()</span>
<span class="k">if</span> <span class="n">USE_CUDA</span><span class="p">:</span>
    <span class="n">capsule_net</span> <span class="o">=</span> <span class="n">capsule_net</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">capsule_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">Mnist</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">30</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="n">capsule_net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train_loader</span><span class="p">):</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">USE_CUDA</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">,</span> <span class="n">masked</span> <span class="o">=</span> <span class="n">capsule_net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">capsule_net</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="s2">&quot;train accuracy:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">masked</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> 
                                   <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="k">print</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>
        
    <span class="n">capsule_net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">test_loader</span><span class="p">):</span>

        <span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">target</span><span class="p">)</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">USE_CUDA</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">target</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">output</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">,</span> <span class="n">masked</span> <span class="o">=</span> <span class="n">capsule_net</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">capsule_net</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reconstructions</span><span class="p">)</span>

        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="s2">&quot;test accuracy:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">masked</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> 
                                   <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    
    <span class="k">print</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">test_loader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>train accuracy: 0.12
train accuracy: 0.9
train accuracy: 0.94
train accuracy: 0.96
train accuracy: 0.99
train accuracy: 0.96
0.229411779922
test accuracy: 0.96
0.0547490972094
train accuracy: 0.98
train accuracy: 0.98
train accuracy: 0.99
train accuracy: 0.99
train accuracy: 1.0
train accuracy: 0.99
0.0456192491871
test accuracy: 0.98
0.0390225026663
train accuracy: 0.99
train accuracy: 0.99
train accuracy: 1.0
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-133-f33ca0acefd3&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span>         optimizer<span class="ansi-blue-fg">.</span>step<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span> 
<span class="ansi-green-fg">---&gt; 24</span><span class="ansi-red-fg">         </span>train_loss <span class="ansi-blue-fg">+=</span> loss<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span> 
<span class="ansi-green-intense-fg ansi-bold">     26</span>         <span class="ansi-green-fg">if</span> batch_id <span class="ansi-blue-fg">%</span> <span class="ansi-cyan-fg">100</span> <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[134]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">plot_images_separately</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
    <span class="s2">&quot;Plot the six MNIST images separately.&quot;</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[135]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">plot_images_separately</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="mi">6</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWQAAABFCAYAAAB9nJwHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[136]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">plot_images_separately</span><span class="p">(</span><span class="n">reconstructions</span><span class="p">[:</span><span class="mi">6</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWQAAABFCAYAAAB9nJwHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    </div>
  </div>
		</div>		
	<div class="resize-sensor" style="position: absolute; left: 0px; top: 0px; right: 0px; bottom: 0px; overflow: hidden; z-index: -1; visibility: hidden;"><div class="resize-sensor-expand" style="position: absolute; left: 0; top: 0; right: 0; bottom: 0; overflow: hidden; z-index: -1; visibility: hidden;"><div style="position: absolute; left: 0px; top: 0px; transition: all 0s ease 0s; width: 100000px; height: 100000px;"></div></div><div class="resize-sensor-shrink" style="position: absolute; left: 0; top: 0; right: 0; bottom: 0; overflow: hidden; z-index: -1; visibility: hidden;"><div style="position: absolute; left: 0; top: 0; transition: 0s; width: 200%; height: 200%"></div></div></div></div>

<!-- /// NOTEBOOK Container -->

    </div>

  </div>
</div>

	<script type="text/javascript" src="js/rAF.js"></script>
	<script type="text/javascript" src="js/ResizeSensor.js"></script>
	<script type="text/javascript" src="js/sticky-sidebar.js"></script>
	<script type="text/javascript" src="js/main.js"></script>

  </body>
</html>